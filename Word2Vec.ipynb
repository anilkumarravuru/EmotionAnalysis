{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>message</th>\n",
       "      <th>fb_like</th>\n",
       "      <th>fb_angry</th>\n",
       "      <th>fb_thankful</th>\n",
       "      <th>fb_haha</th>\n",
       "      <th>fb_sad</th>\n",
       "      <th>fb_wow</th>\n",
       "      <th>fb_love</th>\n",
       "      <th>top_reaction_count</th>\n",
       "      <th>top_reaction</th>\n",
       "      <th>token_words</th>\n",
       "      <th>custom_token_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>This Korean Ad Hilariously Addresses The Power...</td>\n",
       "      <td>But how is this about the burger?</td>\n",
       "      <td>A proof that makeup and sorcery go hand in han...</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>391</td>\n",
       "      <td>fb_haha</td>\n",
       "      <td>korean ad hilari address power makeup gag.tv</td>\n",
       "      <td>korean ad hilari address power makeup gag.tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>People Are Losing It For The Hiddle-Swift Split</td>\n",
       "      <td>Click to see the pic and write a comment...</td>\n",
       "      <td>My imaginary relationship with Tom Hiddleston ...</td>\n",
       "      <td>7606</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>269</td>\n",
       "      <td>1629</td>\n",
       "      <td>fb_haha</td>\n",
       "      <td>peopl lose hiddl swift split</td>\n",
       "      <td>peopl lose hiddl swift split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sia Drops \"The Greatest\" Video Featuring 49 Da...</td>\n",
       "      <td>49 young dancers representing the 49 people lo...</td>\n",
       "      <td>Another amazing and breathtaking video from Si...</td>\n",
       "      <td>25304</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>367</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>fb_love</td>\n",
       "      <td>sia drop greatest video featur dancer pay trib...</td>\n",
       "      <td>sia drop greatest video featur dancer pay trib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15 Tweets That Remind You Why You Need A Condo...</td>\n",
       "      <td>Click to see the pic and write a comment...</td>\n",
       "      <td>They also remind you how great your parents ar...</td>\n",
       "      <td>3452</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>607</td>\n",
       "      <td>fb_haha</td>\n",
       "      <td>tweet remind need condom readi</td>\n",
       "      <td>tweet remind need condom readi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Russian Topless Women Help Stop Speeding Drive...</td>\n",
       "      <td>Is it the breast idea ever?</td>\n",
       "      <td>Not sure of if it will help, or cause more acc...</td>\n",
       "      <td>6454</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1245</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>162</td>\n",
       "      <td>1245</td>\n",
       "      <td>fb_haha</td>\n",
       "      <td>russian topless woman help stop speed driver c...</td>\n",
       "      <td>russian topless woman help stop speed driver c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  This Korean Ad Hilariously Addresses The Power...   \n",
       "1    People Are Losing It For The Hiddle-Swift Split   \n",
       "2  Sia Drops \"The Greatest\" Video Featuring 49 Da...   \n",
       "3  15 Tweets That Remind You Why You Need A Condo...   \n",
       "4  Russian Topless Women Help Stop Speeding Drive...   \n",
       "\n",
       "                                         description  \\\n",
       "0                  But how is this about the burger?   \n",
       "1        Click to see the pic and write a comment...   \n",
       "2  49 young dancers representing the 49 people lo...   \n",
       "3        Click to see the pic and write a comment...   \n",
       "4                        Is it the breast idea ever?   \n",
       "\n",
       "                                             message  fb_like  fb_angry  \\\n",
       "0  A proof that makeup and sorcery go hand in han...     1878         1   \n",
       "1  My imaginary relationship with Tom Hiddleston ...     7606         5   \n",
       "2  Another amazing and breathtaking video from Si...    25304         6   \n",
       "3  They also remind you how great your parents ar...     3452         2   \n",
       "4  Not sure of if it will help, or cause more acc...     6454        12   \n",
       "\n",
       "   fb_thankful  fb_haha  fb_sad  fb_wow  fb_love  top_reaction_count  \\\n",
       "0            0      391       0       3       22                 391   \n",
       "1            0     1629       8      13      269                1629   \n",
       "2            0       95      44     367     2065                2065   \n",
       "3            0      607       0       1       62                 607   \n",
       "4            0     1245       8      93      162                1245   \n",
       "\n",
       "  top_reaction                                        token_words  \\\n",
       "0      fb_haha       korean ad hilari address power makeup gag.tv   \n",
       "1      fb_haha                       peopl lose hiddl swift split   \n",
       "2      fb_love  sia drop greatest video featur dancer pay trib...   \n",
       "3      fb_haha                     tweet remind need condom readi   \n",
       "4      fb_haha  russian topless woman help stop speed driver c...   \n",
       "\n",
       "                                  custom_token_words  \n",
       "0       korean ad hilari address power makeup gag.tv  \n",
       "1                       peopl lose hiddl swift split  \n",
       "2  sia drop greatest video featur dancer pay trib...  \n",
       "3                     tweet remind need condom readi  \n",
       "4  russian topless woman help stop speed driver c...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anil Kumar Ravuru\n",
    "\n",
    "import gensim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69517\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "posts = []\n",
    "for row in df['name'].values:\n",
    "    posts.append(row)\n",
    "tokens, pos_tags = [], []\n",
    "mapper = {'CC': }\n",
    "for sentence in posts:\n",
    "    sent_toks = nltk.word_tokenize(sentences)\n",
    "    pos_toks = nltk.pos_tag(sent_toks)\n",
    "    tokens.append(nltk.word_tokenize(sentences))\n",
    "    pos_tags.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3357706, 3772395)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(tokens, size=50, min_count=1, workers=4)\n",
    "model.train(tokens, total_examples=len(tokens), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48163"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love_NOUN', 0.7010167837142944),\n",
       " ('boyfriend_NOUN', 0.6646912693977356),\n",
       " ('girlfriend_NOUN', 0.6610434651374817),\n",
       " ('lovr_NOUN', 0.6541485786437988),\n",
       " ('fiance_NOUN', 0.6365572214126587)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embedding = '../200/model.bin'\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format(wiki_embedding, binary=True)\n",
    "embeddings.most_similar('lover_NOUN', topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love_NOUN', 0.7010167837142944),\n",
       " ('boyfriend_NOUN', 0.6646912693977356),\n",
       " ('girlfriend_NOUN', 0.6610434651374817),\n",
       " ('lovr_NOUN', 0.6541485786437988),\n",
       " ('fiance_NOUN', 0.6365572214126587)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar('lover_NOUN', topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'lover' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-01174ae0024b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lover'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'lover' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "embeddings['lover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma = 0\n",
    "for x in tokens:\n",
    "    ma = max(ma, len(x))\n",
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_bin = '../GoogleNews-vectors-negative300.bin'\n",
    "g_emb = gensim.models.KeyedVectors.load_word2vec_format(g_bin, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paramour', 0.6798686981201172),\n",
       " ('mistress', 0.6387110948562622),\n",
       " ('boyfriend', 0.6375402212142944),\n",
       " ('lovers', 0.6339589953422546),\n",
       " ('girlfriend', 0.6140860319137573)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_emb.most_similar('lover', topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.12890625e-01, -1.26953125e-01,  3.14941406e-02,  1.70898438e-01,\n",
       "        3.56445312e-02,  3.43750000e-01,  6.64062500e-02,  4.12597656e-02,\n",
       "       -8.93554688e-02, -2.80761719e-02, -7.81250000e-02, -3.94531250e-01,\n",
       "       -2.24609375e-01, -2.01171875e-01,  6.83593750e-02,  2.96875000e-01,\n",
       "       -4.19921875e-02, -1.18164062e-01,  2.79296875e-01, -1.68945312e-01,\n",
       "        2.09960938e-01,  4.78515625e-02,  1.75781250e-01, -1.96289062e-01,\n",
       "        1.31835938e-01, -3.20312500e-01, -2.25585938e-01,  2.63671875e-01,\n",
       "        1.75781250e-02,  5.46875000e-02,  2.51953125e-01,  5.95703125e-02,\n",
       "       -1.76757812e-01,  3.35937500e-01, -8.25195312e-02,  1.22070312e-01,\n",
       "        1.25976562e-01,  2.01171875e-01,  1.73828125e-01,  1.92382812e-01,\n",
       "        5.27343750e-02, -1.44531250e-01,  8.54492188e-02, -1.00097656e-02,\n",
       "        9.94873047e-03, -3.71093750e-01,  1.30859375e-01,  3.00292969e-02,\n",
       "        7.03125000e-02, -7.51953125e-02, -3.12500000e-02,  1.85546875e-01,\n",
       "        2.66113281e-02, -5.56640625e-02, -1.43554688e-01,  8.74023438e-02,\n",
       "       -1.72851562e-01, -2.02148438e-01, -1.01562500e-01,  2.44140625e-01,\n",
       "        1.11816406e-01,  1.41601562e-01, -6.88476562e-02, -1.11694336e-02,\n",
       "       -9.81445312e-02,  9.37500000e-02,  1.59179688e-01, -6.93359375e-02,\n",
       "        1.82617188e-01,  1.22070312e-02,  2.63671875e-01,  1.18652344e-01,\n",
       "       -9.42382812e-02,  5.41992188e-02, -4.58984375e-01,  3.71093750e-01,\n",
       "        1.30615234e-02, -1.42822266e-02, -4.82177734e-03,  1.08398438e-01,\n",
       "       -3.56445312e-02,  1.65039062e-01,  1.81640625e-01, -7.08007812e-02,\n",
       "        9.03320312e-03,  3.06640625e-01, -1.79687500e-01,  3.22265625e-01,\n",
       "        1.44531250e-01,  1.76757812e-01, -1.17187500e-01,  6.64062500e-02,\n",
       "       -2.81250000e-01, -5.90820312e-02, -8.25195312e-02, -7.47070312e-02,\n",
       "        2.16796875e-01, -2.15820312e-01,  1.57226562e-01, -4.85839844e-02,\n",
       "       -2.35351562e-01,  1.55273438e-01,  1.89453125e-01, -2.19726562e-01,\n",
       "        2.15820312e-01, -2.02148438e-01,  4.54101562e-02,  5.56640625e-02,\n",
       "        4.10156250e-02, -3.19824219e-02,  3.90625000e-02,  3.06396484e-02,\n",
       "        3.39843750e-01,  1.10839844e-01,  1.51367188e-01, -1.10839844e-01,\n",
       "       -2.19726562e-01, -2.27539062e-01,  2.69531250e-01,  3.37890625e-01,\n",
       "        4.39453125e-01,  4.29687500e-02, -1.30859375e-01, -1.38671875e-01,\n",
       "        9.57031250e-02, -2.39257812e-01,  1.10351562e-01,  4.85839844e-02,\n",
       "        3.83300781e-02, -4.44335938e-02, -3.06640625e-01,  1.77734375e-01,\n",
       "        1.14135742e-02,  3.18359375e-01, -1.25000000e-01,  8.25195312e-02,\n",
       "        7.86132812e-02,  2.88085938e-02,  3.18359375e-01,  3.47656250e-01,\n",
       "       -5.21850586e-03,  1.56250000e-01, -2.59765625e-01,  2.35351562e-01,\n",
       "       -1.26953125e-01,  1.45507812e-01, -1.13769531e-01,  4.43359375e-01,\n",
       "       -2.33398438e-01, -9.47265625e-02,  5.15625000e-01,  3.83300781e-02,\n",
       "       -6.39648438e-02, -3.95507812e-02, -2.87109375e-01, -1.25976562e-01,\n",
       "       -4.10156250e-02, -1.94091797e-02, -1.10473633e-02, -1.67968750e-01,\n",
       "       -1.16210938e-01,  4.41894531e-02,  1.43554688e-01,  3.45703125e-01,\n",
       "       -2.48046875e-01, -1.12304688e-01,  2.23632812e-01, -9.17968750e-02,\n",
       "       -7.76367188e-02,  7.66601562e-02,  1.39648438e-01,  1.62109375e-01,\n",
       "       -3.63769531e-02, -1.73828125e-01, -6.83593750e-02,  1.23535156e-01,\n",
       "        4.93164062e-02, -1.71875000e-01,  1.38549805e-02,  5.90820312e-02,\n",
       "       -3.78417969e-02, -7.55310059e-04,  2.01171875e-01, -1.94335938e-01,\n",
       "       -1.07421875e-01,  7.12890625e-02, -3.24707031e-02, -1.06445312e-01,\n",
       "        1.11328125e-01, -7.51953125e-02,  9.03320312e-02, -5.64575195e-03,\n",
       "        9.42382812e-02,  3.43750000e-01,  1.42578125e-01,  4.17968750e-01,\n",
       "       -4.29687500e-02, -8.00781250e-02, -5.95703125e-02,  1.36718750e-01,\n",
       "       -3.41796875e-02, -2.91015625e-01, -1.94335938e-01, -1.09375000e-01,\n",
       "        1.55273438e-01, -1.13281250e-01, -1.64062500e-01,  1.69921875e-01,\n",
       "       -9.08203125e-02, -2.55859375e-01, -1.95312500e-01,  4.66308594e-02,\n",
       "        6.59179688e-02,  4.46777344e-02, -4.19921875e-01,  6.29882812e-02,\n",
       "        9.91210938e-02,  1.18164062e-01, -1.42578125e-01,  3.80859375e-02,\n",
       "        5.81054688e-02, -1.36108398e-02,  1.14257812e-01,  2.12890625e-01,\n",
       "        2.24609375e-02, -6.44531250e-02,  1.24511719e-01, -2.37304688e-01,\n",
       "       -8.39843750e-02, -8.88671875e-02, -2.08007812e-01,  1.16577148e-02,\n",
       "       -2.91015625e-01, -3.80859375e-02,  3.20312500e-01, -1.12792969e-01,\n",
       "        3.80859375e-02,  1.38671875e-01, -4.88281250e-01, -1.87500000e-01,\n",
       "        2.23632812e-01, -1.30859375e-01, -1.39648438e-01,  2.79296875e-01,\n",
       "        2.15820312e-01,  2.04101562e-01, -2.08740234e-02, -1.83593750e-01,\n",
       "        1.92382812e-01, -6.20117188e-02,  6.17675781e-02,  3.37890625e-01,\n",
       "        1.92871094e-02,  8.39843750e-02,  5.24902344e-02,  6.00585938e-02,\n",
       "       -1.95312500e-01, -1.94335938e-01, -3.43750000e-01,  6.12792969e-02,\n",
       "       -1.68945312e-01, -9.42382812e-02, -7.27539062e-02, -1.55273438e-01,\n",
       "       -5.71289062e-02,  3.58886719e-02, -2.32421875e-01,  1.05468750e-01,\n",
       "       -5.10253906e-02,  1.65039062e-01,  6.40869141e-03,  5.85937500e-02,\n",
       "       -1.64062500e-01,  1.57226562e-01, -1.58203125e-01, -1.15722656e-01,\n",
       "       -1.73828125e-01,  1.74804688e-01, -1.16210938e-01,  1.19209290e-04,\n",
       "        1.98242188e-01, -1.43554688e-01,  1.84570312e-01,  3.97949219e-02,\n",
       "        2.03125000e-01,  5.41992188e-02, -2.83203125e-01, -1.50390625e-01,\n",
       "        1.87500000e-01,  3.65234375e-01,  5.12695312e-02,  9.37500000e-02,\n",
       "       -3.24218750e-01, -2.22656250e-01,  7.32421875e-02, -2.48046875e-01,\n",
       "       -3.66210938e-02, -3.85742188e-02, -1.94335938e-01,  4.95605469e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_emb['lover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.073544</td>\n",
       "      <td>0.108913</td>\n",
       "      <td>0.160871</td>\n",
       "      <td>0.034072</td>\n",
       "      <td>-0.013637</td>\n",
       "      <td>0.041472</td>\n",
       "      <td>0.220081</td>\n",
       "      <td>-0.125604</td>\n",
       "      <td>-0.024750</td>\n",
       "      <td>1.068500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061121</td>\n",
       "      <td>0.104532</td>\n",
       "      <td>0.183005</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>-0.121143</td>\n",
       "      <td>-0.093114</td>\n",
       "      <td>-0.125426</td>\n",
       "      <td>-0.058837</td>\n",
       "      <td>0.105520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.195056</td>\n",
       "      <td>0.108406</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>-0.090817</td>\n",
       "      <td>0.012558</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>-0.030732</td>\n",
       "      <td>0.071714</td>\n",
       "      <td>1.327380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034682</td>\n",
       "      <td>-0.023684</td>\n",
       "      <td>-0.111624</td>\n",
       "      <td>-0.242066</td>\n",
       "      <td>-0.037542</td>\n",
       "      <td>0.248412</td>\n",
       "      <td>-0.027789</td>\n",
       "      <td>-0.147978</td>\n",
       "      <td>-0.007314</td>\n",
       "      <td>-0.029654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.224312</td>\n",
       "      <td>0.076502</td>\n",
       "      <td>0.054447</td>\n",
       "      <td>-0.072843</td>\n",
       "      <td>0.168919</td>\n",
       "      <td>-0.138395</td>\n",
       "      <td>0.053339</td>\n",
       "      <td>-0.149023</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>1.334516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092629</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>-0.062576</td>\n",
       "      <td>-0.102133</td>\n",
       "      <td>0.160570</td>\n",
       "      <td>-0.048921</td>\n",
       "      <td>-0.086407</td>\n",
       "      <td>-0.113276</td>\n",
       "      <td>0.129490</td>\n",
       "      <td>0.140914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116941</td>\n",
       "      <td>-0.030174</td>\n",
       "      <td>-0.214916</td>\n",
       "      <td>0.094865</td>\n",
       "      <td>-0.281915</td>\n",
       "      <td>-0.057896</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>-0.237638</td>\n",
       "      <td>-0.006954</td>\n",
       "      <td>1.329428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061786</td>\n",
       "      <td>0.116650</td>\n",
       "      <td>-0.029218</td>\n",
       "      <td>0.036852</td>\n",
       "      <td>0.170142</td>\n",
       "      <td>0.023399</td>\n",
       "      <td>-0.233284</td>\n",
       "      <td>0.036698</td>\n",
       "      <td>-0.015935</td>\n",
       "      <td>0.191664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.140794</td>\n",
       "      <td>0.177248</td>\n",
       "      <td>-0.144513</td>\n",
       "      <td>0.091202</td>\n",
       "      <td>0.016033</td>\n",
       "      <td>0.041583</td>\n",
       "      <td>0.156570</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>-0.032524</td>\n",
       "      <td>1.489943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038334</td>\n",
       "      <td>-0.142692</td>\n",
       "      <td>0.250195</td>\n",
       "      <td>-0.186694</td>\n",
       "      <td>0.115697</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.115752</td>\n",
       "      <td>-0.029703</td>\n",
       "      <td>-0.063365</td>\n",
       "      <td>0.047542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.073544  0.108913  0.160871  0.034072 -0.013637  0.041472  0.220081   \n",
       "1 -0.195056  0.108406  0.015291  0.007698 -0.090817  0.012558  0.024710   \n",
       "2 -0.224312  0.076502  0.054447 -0.072843  0.168919 -0.138395  0.053339   \n",
       "3  0.116941 -0.030174 -0.214916  0.094865 -0.281915 -0.057896  0.014347   \n",
       "4 -0.140794  0.177248 -0.144513  0.091202  0.016033  0.041583  0.156570   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.125604 -0.024750  1.068500  ... -0.061121  0.104532  0.183005  0.004923   \n",
       "1 -0.030732  0.071714  1.327380  ... -0.034682 -0.023684 -0.111624 -0.242066   \n",
       "2 -0.149023 -0.010294  1.334516  ... -0.092629 -0.001183 -0.062576 -0.102133   \n",
       "3 -0.237638 -0.006954  1.329428  ...  0.061786  0.116650 -0.029218  0.036852   \n",
       "4 -0.157780 -0.032524  1.489943  ... -0.038334 -0.142692  0.250195 -0.186694   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.025700 -0.121143 -0.093114 -0.125426 -0.058837  0.105520  \n",
       "1 -0.037542  0.248412 -0.027789 -0.147978 -0.007314 -0.029654  \n",
       "2  0.160570 -0.048921 -0.086407 -0.113276  0.129490  0.140914  \n",
       "3  0.170142  0.023399 -0.233284  0.036698 -0.015935  0.191664  \n",
       "4  0.115697  0.002057  0.115752 -0.029703 -0.063365  0.047542  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df = pd.read_csv('spacy_embeds.csv', header=None)\n",
    "embed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = df.top_reaction\n",
    "train_features, rest_features, train_labels, rest_labels = train_test_split(embed_df, labels, test_size=.1, random_state=6848)\n",
    "val_features, test_features, val_labels, test_labels = train_test_split(rest_features, rest_labels, test_size=.7, random_state=6848)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*120))\n",
    "    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\"*80)\n",
    "    return accuracy, train_test_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfeature_accuracy_checker(classifier=LogisticRegression(C=2.0, multi_class='ovr')):\n",
    "    result = []\n",
    "    print (classifier)\n",
    "    print(\"\\n\")\n",
    "    checker_pipeline = Pipeline([('classifier', classifier)])\n",
    "    print(\"Validation result for {} features\".format(300))\n",
    "    nfeature_accuracy,tt_time = accuracy_summary(checker_pipeline, train_features, train_labels, val_features, val_labels)\n",
    "    result.append((300, nfeature_accuracy, tt_time))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 300 features\n",
      "accuracy score: 60.14%\n",
      "train and test time: 41.56s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "feature_result_bgt = nfeature_accuracy_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "\n",
      "\n",
      "Validation result for 300 features\n",
      "accuracy score: 59.63%\n",
      "train and test time: 577.68s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier = LinearSVC(C=1.5, multi_class='ovr')\n",
    "feature_result_bgt = nfeature_accuracy_checker(classifier=classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
